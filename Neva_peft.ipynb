{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b447da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PEFT Finetuning the MultiModal with NeMo\n",
    "## Step 1: Prerequisites:\n",
    "#Clone NeMo framework with yuya2403_neva_patch. Please note that this patch is needed for NeVa PEFT Finetuning. It will be available with NeMo container in next release:\n",
    "\n",
    "#git clone https://github.com/NVIDIA/NeMo.git\n",
    "\n",
    "#git checkout yuya/2403_neva_patch\n",
    "\n",
    "#Download the datase:\n",
    "\n",
    "#Instruction Tuning Dataset The instruction tuning annotations are sourced from the LLaVA implementation and are available here.\n",
    "\n",
    "#The associated images for the mixture instruction tuning annotations can be found here. After extracting, the data should be formatted as follows:\n",
    "'''\n",
    "    images\n",
    "      ├── coco\n",
    "      │    └── train2017\n",
    "      ├── gqa\n",
    "      │    └── images\n",
    "      ├── ocr_vqa\n",
    "      │    └── images\n",
    "      ├── textvqa\n",
    "      │    └── train_images\n",
    "      └── vg\n",
    "           ├── VG_100K\n",
    "           └── VG_100K_2\n",
    "'''\n",
    "#The data folder will look like this:\n",
    "'''\n",
    "LLaVA-Instruct-mixture\n",
    "├── llava_v1_5_mix665k.json\n",
    "└── images\n",
    "    └── ...\n",
    "'''\n",
    "\n",
    "#Download NeMo container from NGC\n",
    "'''\n",
    "docker run --gpus all -it --rm  -v /raid/LLaVA-Instruct-mixture:/home -v /home/NeMo:/opt/NeMo -v /home/finetune:/home --shm-size=8g -p 8888:8888 --ulimit memlock=-1 --ulimit  stack=67108864 nvcr.io/nvidia/nemo:24.03.01.framework\n",
    "Here, assumption is that you have the data copied to raid/LLaVA-Instruct-mixture and this notebook is inside /home/finetune and the NeMo FW you cloned is at /home/NeMo\n",
    "'''\n",
    "\n",
    "#Download LLaVa model.\n",
    "#Atleast One A100 is needed for the finetuning. Find more info on https://docs.nvidia.com/nemo-framework/user-guide/latest/multimodalmodels/multimodallanguagemodel/neva/peft.html\n",
    "#This is the assumption that you are running this notebook inside the NeMo container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68a3e533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'sentencepiece' already exists and is not an empty directory.\n",
      "mkdir: cannot create directory ‘build’: File exists\n",
      "[ 35%] Built target sentencepiece\n",
      "[ 45%] Built target sentencepiece_train\n",
      "[ 81%] Built target sentencepiece-static\n",
      "[ 91%] Built target sentencepiece_train-static\n",
      "[ 93%] Built target spm_encode\n",
      "[ 94%] Built target spm_decode\n",
      "[ 96%] Built target spm_normalize\n",
      "[ 98%] Built target spm_train\n",
      "[100%] Built target spm_export_vocab\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"\"\n",
      "-- Up-to-date: /usr/local/lib/pkgconfig/sentencepiece.pc\n",
      "-- Up-to-date: /usr/local/lib/libsentencepiece.so.0.0.0\n",
      "-- Up-to-date: /usr/local/lib/libsentencepiece.so.0\n",
      "-- Up-to-date: /usr/local/lib/libsentencepiece.so\n",
      "-- Up-to-date: /usr/local/lib/libsentencepiece_train.so.0.0.0\n",
      "-- Up-to-date: /usr/local/lib/libsentencepiece_train.so.0\n",
      "-- Up-to-date: /usr/local/lib/libsentencepiece_train.so\n",
      "-- Up-to-date: /usr/local/lib/libsentencepiece.a\n",
      "-- Up-to-date: /usr/local/lib/libsentencepiece_train.a\n",
      "-- Up-to-date: /usr/local/bin/spm_encode\n",
      "-- Up-to-date: /usr/local/bin/spm_decode\n",
      "-- Up-to-date: /usr/local/bin/spm_normalize\n",
      "-- Up-to-date: /usr/local/bin/spm_train\n",
      "-- Up-to-date: /usr/local/bin/spm_export_vocab\n",
      "-- Up-to-date: /usr/local/include/sentencepiece_trainer.h\n",
      "-- Up-to-date: /usr/local/include/sentencepiece_processor.h\n"
     ]
    }
   ],
   "source": [
    "## Step 2: Install sentencepiece\n",
    "# Clone the sentencepiece repository and install it\n",
    "!cd /opt && git clone https://github.com/google/sentencepiece.git\n",
    "\n",
    "# Create the build directory and compile sentencepiece\n",
    "!cd /opt/sentencepiece && mkdir build && cd build && cmake .. && make\n",
    "\n",
    "# Install the compiled binaries and update the shared library cache\n",
    "!cd /opt/sentencepiece/build && make install && ldconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dacb7616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created token '<extra_id_0>' at ID 32000\n",
      "INFO: Created token '<extra_id_1>' at ID 32001\n",
      "INFO: Created token '<extra_id_2>' at ID 32002\n",
      "INFO: Created token '<extra_id_3>' at ID 32003\n",
      "INFO: Created token '<extra_id_4>' at ID 32004\n",
      "INFO: Created token '<extra_id_5>' at ID 32005\n",
      "INFO: Created token '<extra_id_6>' at ID 32006\n",
      "INFO: Created token '<extra_id_7>' at ID 32007\n",
      "INFO: New tokenizer vocab size: 32008\n",
      "INFO: Created new tokenizer at: /home/llava-v1.5-13b/tokenizer_neva.model\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Update Tokenizer\n",
    "# Generate Python files from the protocol buffer definition\n",
    "!cd /opt/sentencepiece/src && protoc --python_out=/opt/NeMo/scripts/tokenizers/ sentencepiece_model.proto\n",
    "\n",
    "# Run the Python script to add special tokens for media postions in multi-modal to the sentencepiece model\n",
    "!python /opt/NeMo/scripts/tokenizers/add_special_tokens_to_sentencepiece.py \\\n",
    "--input_file /home/llava-v1.5-13b/tokenizer.model \\\n",
    "--output_file /home/llava-v1.5-13b/tokenizer_neva.model \\\n",
    "--is_userdefined \\\n",
    "--tokens \"<extra_id_0>\" \"<extra_id_1>\" \"<extra_id_2>\" \"<extra_id_3>\" \\\n",
    "\"<extra_id_4>\" \"<extra_id_5>\" \"<extra_id_6>\" \"<extra_id_7>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d329cf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'LLaVA' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "## Step 4: Install LLaVa\n",
    "# Change directory to /home\n",
    "!cd /home\n",
    "\n",
    "# Clone the LLaVa repository\n",
    "!git clone https://github.com/haotian-liu/LLaVA.git\n",
    "\n",
    "# Set the PYTHONPATH environment variable\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = os.environ.get('PYTHONPATH', '') + ':/home/LLaVA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc51256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention Installed\n",
      "[NeMo W 2024-05-27 22:12:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo I 2024-05-27 22:12:31 convert_hf_llava_to_neva:153] loading checkpoint /home/llava-v1.5-13b\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:03<00:00,  1.32s/it]\n",
      "hf_config: {'vocab_size': 32000, 'max_position_embeddings': 4096, 'hidden_size': 5120, 'intermediate_size': 13824, 'num_hidden_layers': 40, 'num_attention_heads': 40, 'num_key_value_heads': 40, 'hidden_act': 'silu', 'initializer_range': 0.02, 'rms_norm_eps': 1e-05, 'pretraining_tp': 1, 'use_cache': True, 'rope_theta': 10000.0, 'rope_scaling': None, 'attention_bias': False, 'attention_dropout': 0.0, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': torch.float16, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': False, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 4096, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['LlavaLlamaForCausalLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 1, 'pad_token_id': 0, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '/home/llava-v1.5-13b', '_commit_hash': None, '_attn_implementation_internal': 'sdpa', 'transformers_version': '4.31.0', 'freeze_mm_mlp_adapter': False, 'freeze_mm_vision_resampler': False, 'image_aspect_ratio': 'pad', 'mm_hidden_size': 1024, 'mm_projector_type': 'mlp2x_gelu', 'mm_resampler_type': None, 'mm_use_im_patch_token': False, 'mm_use_im_start_end': False, 'mm_vision_select_feature': 'patch', 'mm_vision_select_layer': -2, 'mm_vision_tower': 'openai/clip-vit-large-patch14-336', 'model_type': 'llava', 'tune_mm_mlp_adapter': False, 'tune_mm_vision_resampler': False, 'unfreeze_mm_vision_tower': False, 'use_mm_proj': True, 'tokenizer_model': '/home/llava-v1.5-13b/tokenizer.model'}\n",
      "named parameters:\n",
      "- model.embed_tokens.weight\n",
      "- model.layers.0.self_attn.q_proj.weight\n",
      "- model.layers.0.self_attn.k_proj.weight\n",
      "- model.layers.0.self_attn.v_proj.weight\n",
      "- model.layers.0.self_attn.o_proj.weight\n",
      "- model.layers.0.mlp.gate_proj.weight\n",
      "- model.layers.0.mlp.up_proj.weight\n",
      "- model.layers.0.mlp.down_proj.weight\n",
      "- model.layers.0.input_layernorm.weight\n",
      "- model.layers.0.post_attention_layernorm.weight\n",
      "- model.layers.1.self_attn.q_proj.weight\n",
      "- model.layers.1.self_attn.k_proj.weight\n",
      "- model.layers.1.self_attn.v_proj.weight\n",
      "- model.layers.1.self_attn.o_proj.weight\n",
      "- model.layers.1.mlp.gate_proj.weight\n",
      "- model.layers.1.mlp.up_proj.weight\n",
      "- model.layers.1.mlp.down_proj.weight\n",
      "- model.layers.1.input_layernorm.weight\n",
      "- model.layers.1.post_attention_layernorm.weight\n",
      "- model.layers.2.self_attn.q_proj.weight\n",
      "- model.layers.2.self_attn.k_proj.weight\n",
      "- model.layers.2.self_attn.v_proj.weight\n",
      "- model.layers.2.self_attn.o_proj.weight\n",
      "- model.layers.2.mlp.gate_proj.weight\n",
      "- model.layers.2.mlp.up_proj.weight\n",
      "- model.layers.2.mlp.down_proj.weight\n",
      "- model.layers.2.input_layernorm.weight\n",
      "- model.layers.2.post_attention_layernorm.weight\n",
      "- model.layers.3.self_attn.q_proj.weight\n",
      "- model.layers.3.self_attn.k_proj.weight\n",
      "- model.layers.3.self_attn.v_proj.weight\n",
      "- model.layers.3.self_attn.o_proj.weight\n",
      "- model.layers.3.mlp.gate_proj.weight\n",
      "- model.layers.3.mlp.up_proj.weight\n",
      "- model.layers.3.mlp.down_proj.weight\n",
      "- model.layers.3.input_layernorm.weight\n",
      "- model.layers.3.post_attention_layernorm.weight\n",
      "- model.layers.4.self_attn.q_proj.weight\n",
      "- model.layers.4.self_attn.k_proj.weight\n",
      "- model.layers.4.self_attn.v_proj.weight\n",
      "- model.layers.4.self_attn.o_proj.weight\n",
      "- model.layers.4.mlp.gate_proj.weight\n",
      "- model.layers.4.mlp.up_proj.weight\n",
      "- model.layers.4.mlp.down_proj.weight\n",
      "- model.layers.4.input_layernorm.weight\n",
      "- model.layers.4.post_attention_layernorm.weight\n",
      "- model.layers.5.self_attn.q_proj.weight\n",
      "- model.layers.5.self_attn.k_proj.weight\n",
      "- model.layers.5.self_attn.v_proj.weight\n",
      "- model.layers.5.self_attn.o_proj.weight\n",
      "- model.layers.5.mlp.gate_proj.weight\n",
      "- model.layers.5.mlp.up_proj.weight\n",
      "- model.layers.5.mlp.down_proj.weight\n",
      "- model.layers.5.input_layernorm.weight\n",
      "- model.layers.5.post_attention_layernorm.weight\n",
      "- model.layers.6.self_attn.q_proj.weight\n",
      "- model.layers.6.self_attn.k_proj.weight\n",
      "- model.layers.6.self_attn.v_proj.weight\n",
      "- model.layers.6.self_attn.o_proj.weight\n",
      "- model.layers.6.mlp.gate_proj.weight\n",
      "- model.layers.6.mlp.up_proj.weight\n",
      "- model.layers.6.mlp.down_proj.weight\n",
      "- model.layers.6.input_layernorm.weight\n",
      "- model.layers.6.post_attention_layernorm.weight\n",
      "- model.layers.7.self_attn.q_proj.weight\n",
      "- model.layers.7.self_attn.k_proj.weight\n",
      "- model.layers.7.self_attn.v_proj.weight\n",
      "- model.layers.7.self_attn.o_proj.weight\n",
      "- model.layers.7.mlp.gate_proj.weight\n",
      "- model.layers.7.mlp.up_proj.weight\n",
      "- model.layers.7.mlp.down_proj.weight\n",
      "- model.layers.7.input_layernorm.weight\n",
      "- model.layers.7.post_attention_layernorm.weight\n",
      "- model.layers.8.self_attn.q_proj.weight\n",
      "- model.layers.8.self_attn.k_proj.weight\n",
      "- model.layers.8.self_attn.v_proj.weight\n",
      "- model.layers.8.self_attn.o_proj.weight\n",
      "- model.layers.8.mlp.gate_proj.weight\n",
      "- model.layers.8.mlp.up_proj.weight\n",
      "- model.layers.8.mlp.down_proj.weight\n",
      "- model.layers.8.input_layernorm.weight\n",
      "- model.layers.8.post_attention_layernorm.weight\n",
      "- model.layers.9.self_attn.q_proj.weight\n",
      "- model.layers.9.self_attn.k_proj.weight\n",
      "- model.layers.9.self_attn.v_proj.weight\n",
      "- model.layers.9.self_attn.o_proj.weight\n",
      "- model.layers.9.mlp.gate_proj.weight\n",
      "- model.layers.9.mlp.up_proj.weight\n",
      "- model.layers.9.mlp.down_proj.weight\n",
      "- model.layers.9.input_layernorm.weight\n",
      "- model.layers.9.post_attention_layernorm.weight\n",
      "- model.layers.10.self_attn.q_proj.weight\n",
      "- model.layers.10.self_attn.k_proj.weight\n",
      "- model.layers.10.self_attn.v_proj.weight\n",
      "- model.layers.10.self_attn.o_proj.weight\n",
      "- model.layers.10.mlp.gate_proj.weight\n",
      "- model.layers.10.mlp.up_proj.weight\n",
      "- model.layers.10.mlp.down_proj.weight\n",
      "- model.layers.10.input_layernorm.weight\n",
      "- model.layers.10.post_attention_layernorm.weight\n",
      "- model.layers.11.self_attn.q_proj.weight\n",
      "- model.layers.11.self_attn.k_proj.weight\n",
      "- model.layers.11.self_attn.v_proj.weight\n",
      "- model.layers.11.self_attn.o_proj.weight\n",
      "- model.layers.11.mlp.gate_proj.weight\n",
      "- model.layers.11.mlp.up_proj.weight\n",
      "- model.layers.11.mlp.down_proj.weight\n",
      "- model.layers.11.input_layernorm.weight\n",
      "- model.layers.11.post_attention_layernorm.weight\n",
      "- model.layers.12.self_attn.q_proj.weight\n",
      "- model.layers.12.self_attn.k_proj.weight\n",
      "- model.layers.12.self_attn.v_proj.weight\n",
      "- model.layers.12.self_attn.o_proj.weight\n",
      "- model.layers.12.mlp.gate_proj.weight\n",
      "- model.layers.12.mlp.up_proj.weight\n",
      "- model.layers.12.mlp.down_proj.weight\n",
      "- model.layers.12.input_layernorm.weight\n",
      "- model.layers.12.post_attention_layernorm.weight\n",
      "- model.layers.13.self_attn.q_proj.weight\n",
      "- model.layers.13.self_attn.k_proj.weight\n",
      "- model.layers.13.self_attn.v_proj.weight\n",
      "- model.layers.13.self_attn.o_proj.weight\n",
      "- model.layers.13.mlp.gate_proj.weight\n",
      "- model.layers.13.mlp.up_proj.weight\n",
      "- model.layers.13.mlp.down_proj.weight\n",
      "- model.layers.13.input_layernorm.weight\n",
      "- model.layers.13.post_attention_layernorm.weight\n",
      "- model.layers.14.self_attn.q_proj.weight\n",
      "- model.layers.14.self_attn.k_proj.weight\n",
      "- model.layers.14.self_attn.v_proj.weight\n",
      "- model.layers.14.self_attn.o_proj.weight\n",
      "- model.layers.14.mlp.gate_proj.weight\n",
      "- model.layers.14.mlp.up_proj.weight\n",
      "- model.layers.14.mlp.down_proj.weight\n",
      "- model.layers.14.input_layernorm.weight\n",
      "- model.layers.14.post_attention_layernorm.weight\n",
      "- model.layers.15.self_attn.q_proj.weight\n",
      "- model.layers.15.self_attn.k_proj.weight\n",
      "- model.layers.15.self_attn.v_proj.weight\n",
      "- model.layers.15.self_attn.o_proj.weight\n",
      "- model.layers.15.mlp.gate_proj.weight\n",
      "- model.layers.15.mlp.up_proj.weight\n",
      "- model.layers.15.mlp.down_proj.weight\n",
      "- model.layers.15.input_layernorm.weight\n",
      "- model.layers.15.post_attention_layernorm.weight\n",
      "- model.layers.16.self_attn.q_proj.weight\n",
      "- model.layers.16.self_attn.k_proj.weight\n",
      "- model.layers.16.self_attn.v_proj.weight\n",
      "- model.layers.16.self_attn.o_proj.weight\n",
      "- model.layers.16.mlp.gate_proj.weight\n",
      "- model.layers.16.mlp.up_proj.weight\n",
      "- model.layers.16.mlp.down_proj.weight\n",
      "- model.layers.16.input_layernorm.weight\n",
      "- model.layers.16.post_attention_layernorm.weight\n",
      "- model.layers.17.self_attn.q_proj.weight\n",
      "- model.layers.17.self_attn.k_proj.weight\n",
      "- model.layers.17.self_attn.v_proj.weight\n",
      "- model.layers.17.self_attn.o_proj.weight\n",
      "- model.layers.17.mlp.gate_proj.weight\n",
      "- model.layers.17.mlp.up_proj.weight\n",
      "- model.layers.17.mlp.down_proj.weight\n",
      "- model.layers.17.input_layernorm.weight\n",
      "- model.layers.17.post_attention_layernorm.weight\n",
      "- model.layers.18.self_attn.q_proj.weight\n",
      "- model.layers.18.self_attn.k_proj.weight\n",
      "- model.layers.18.self_attn.v_proj.weight\n",
      "- model.layers.18.self_attn.o_proj.weight\n",
      "- model.layers.18.mlp.gate_proj.weight\n",
      "- model.layers.18.mlp.up_proj.weight\n",
      "- model.layers.18.mlp.down_proj.weight\n",
      "- model.layers.18.input_layernorm.weight\n",
      "- model.layers.18.post_attention_layernorm.weight\n",
      "- model.layers.19.self_attn.q_proj.weight\n",
      "- model.layers.19.self_attn.k_proj.weight\n",
      "- model.layers.19.self_attn.v_proj.weight\n",
      "- model.layers.19.self_attn.o_proj.weight\n",
      "- model.layers.19.mlp.gate_proj.weight\n",
      "- model.layers.19.mlp.up_proj.weight\n",
      "- model.layers.19.mlp.down_proj.weight\n",
      "- model.layers.19.input_layernorm.weight\n",
      "- model.layers.19.post_attention_layernorm.weight\n",
      "- model.layers.20.self_attn.q_proj.weight\n",
      "- model.layers.20.self_attn.k_proj.weight\n",
      "- model.layers.20.self_attn.v_proj.weight\n",
      "- model.layers.20.self_attn.o_proj.weight\n",
      "- model.layers.20.mlp.gate_proj.weight\n",
      "- model.layers.20.mlp.up_proj.weight\n",
      "- model.layers.20.mlp.down_proj.weight\n",
      "- model.layers.20.input_layernorm.weight\n",
      "- model.layers.20.post_attention_layernorm.weight\n",
      "- model.layers.21.self_attn.q_proj.weight\n",
      "- model.layers.21.self_attn.k_proj.weight\n",
      "- model.layers.21.self_attn.v_proj.weight\n",
      "- model.layers.21.self_attn.o_proj.weight\n",
      "- model.layers.21.mlp.gate_proj.weight\n",
      "- model.layers.21.mlp.up_proj.weight\n",
      "- model.layers.21.mlp.down_proj.weight\n",
      "- model.layers.21.input_layernorm.weight\n",
      "- model.layers.21.post_attention_layernorm.weight\n",
      "- model.layers.22.self_attn.q_proj.weight\n",
      "- model.layers.22.self_attn.k_proj.weight\n",
      "- model.layers.22.self_attn.v_proj.weight\n",
      "- model.layers.22.self_attn.o_proj.weight\n",
      "- model.layers.22.mlp.gate_proj.weight\n",
      "- model.layers.22.mlp.up_proj.weight\n",
      "- model.layers.22.mlp.down_proj.weight\n",
      "- model.layers.22.input_layernorm.weight\n",
      "- model.layers.22.post_attention_layernorm.weight\n",
      "- model.layers.23.self_attn.q_proj.weight\n",
      "- model.layers.23.self_attn.k_proj.weight\n",
      "- model.layers.23.self_attn.v_proj.weight\n",
      "- model.layers.23.self_attn.o_proj.weight\n",
      "- model.layers.23.mlp.gate_proj.weight\n",
      "- model.layers.23.mlp.up_proj.weight\n",
      "- model.layers.23.mlp.down_proj.weight\n",
      "- model.layers.23.input_layernorm.weight\n",
      "- model.layers.23.post_attention_layernorm.weight\n",
      "- model.layers.24.self_attn.q_proj.weight\n",
      "- model.layers.24.self_attn.k_proj.weight\n",
      "- model.layers.24.self_attn.v_proj.weight\n",
      "- model.layers.24.self_attn.o_proj.weight\n",
      "- model.layers.24.mlp.gate_proj.weight\n",
      "- model.layers.24.mlp.up_proj.weight\n",
      "- model.layers.24.mlp.down_proj.weight\n",
      "- model.layers.24.input_layernorm.weight\n",
      "- model.layers.24.post_attention_layernorm.weight\n",
      "- model.layers.25.self_attn.q_proj.weight\n",
      "- model.layers.25.self_attn.k_proj.weight\n",
      "- model.layers.25.self_attn.v_proj.weight\n",
      "- model.layers.25.self_attn.o_proj.weight\n",
      "- model.layers.25.mlp.gate_proj.weight\n",
      "- model.layers.25.mlp.up_proj.weight\n",
      "- model.layers.25.mlp.down_proj.weight\n",
      "- model.layers.25.input_layernorm.weight\n",
      "- model.layers.25.post_attention_layernorm.weight\n",
      "- model.layers.26.self_attn.q_proj.weight\n",
      "- model.layers.26.self_attn.k_proj.weight\n",
      "- model.layers.26.self_attn.v_proj.weight\n",
      "- model.layers.26.self_attn.o_proj.weight\n",
      "- model.layers.26.mlp.gate_proj.weight\n",
      "- model.layers.26.mlp.up_proj.weight\n",
      "- model.layers.26.mlp.down_proj.weight\n",
      "- model.layers.26.input_layernorm.weight\n",
      "- model.layers.26.post_attention_layernorm.weight\n",
      "- model.layers.27.self_attn.q_proj.weight\n",
      "- model.layers.27.self_attn.k_proj.weight\n",
      "- model.layers.27.self_attn.v_proj.weight\n",
      "- model.layers.27.self_attn.o_proj.weight\n",
      "- model.layers.27.mlp.gate_proj.weight\n",
      "- model.layers.27.mlp.up_proj.weight\n",
      "- model.layers.27.mlp.down_proj.weight\n",
      "- model.layers.27.input_layernorm.weight\n",
      "- model.layers.27.post_attention_layernorm.weight\n",
      "- model.layers.28.self_attn.q_proj.weight\n",
      "- model.layers.28.self_attn.k_proj.weight\n",
      "- model.layers.28.self_attn.v_proj.weight\n",
      "- model.layers.28.self_attn.o_proj.weight\n",
      "- model.layers.28.mlp.gate_proj.weight\n",
      "- model.layers.28.mlp.up_proj.weight\n",
      "- model.layers.28.mlp.down_proj.weight\n",
      "- model.layers.28.input_layernorm.weight\n",
      "- model.layers.28.post_attention_layernorm.weight\n",
      "- model.layers.29.self_attn.q_proj.weight\n",
      "- model.layers.29.self_attn.k_proj.weight\n",
      "- model.layers.29.self_attn.v_proj.weight\n",
      "- model.layers.29.self_attn.o_proj.weight\n",
      "- model.layers.29.mlp.gate_proj.weight\n",
      "- model.layers.29.mlp.up_proj.weight\n",
      "- model.layers.29.mlp.down_proj.weight\n",
      "- model.layers.29.input_layernorm.weight\n",
      "- model.layers.29.post_attention_layernorm.weight\n",
      "- model.layers.30.self_attn.q_proj.weight\n",
      "- model.layers.30.self_attn.k_proj.weight\n",
      "- model.layers.30.self_attn.v_proj.weight\n",
      "- model.layers.30.self_attn.o_proj.weight\n",
      "- model.layers.30.mlp.gate_proj.weight\n",
      "- model.layers.30.mlp.up_proj.weight\n",
      "- model.layers.30.mlp.down_proj.weight\n",
      "- model.layers.30.input_layernorm.weight\n",
      "- model.layers.30.post_attention_layernorm.weight\n",
      "- model.layers.31.self_attn.q_proj.weight\n",
      "- model.layers.31.self_attn.k_proj.weight\n",
      "- model.layers.31.self_attn.v_proj.weight\n",
      "- model.layers.31.self_attn.o_proj.weight\n",
      "- model.layers.31.mlp.gate_proj.weight\n",
      "- model.layers.31.mlp.up_proj.weight\n",
      "- model.layers.31.mlp.down_proj.weight\n",
      "- model.layers.31.input_layernorm.weight\n",
      "- model.layers.31.post_attention_layernorm.weight\n",
      "- model.layers.32.self_attn.q_proj.weight\n",
      "- model.layers.32.self_attn.k_proj.weight\n",
      "- model.layers.32.self_attn.v_proj.weight\n",
      "- model.layers.32.self_attn.o_proj.weight\n",
      "- model.layers.32.mlp.gate_proj.weight\n",
      "- model.layers.32.mlp.up_proj.weight\n",
      "- model.layers.32.mlp.down_proj.weight\n",
      "- model.layers.32.input_layernorm.weight\n",
      "- model.layers.32.post_attention_layernorm.weight\n",
      "- model.layers.33.self_attn.q_proj.weight\n",
      "- model.layers.33.self_attn.k_proj.weight\n",
      "- model.layers.33.self_attn.v_proj.weight\n",
      "- model.layers.33.self_attn.o_proj.weight\n",
      "- model.layers.33.mlp.gate_proj.weight\n",
      "- model.layers.33.mlp.up_proj.weight\n",
      "- model.layers.33.mlp.down_proj.weight\n",
      "- model.layers.33.input_layernorm.weight\n",
      "- model.layers.33.post_attention_layernorm.weight\n",
      "- model.layers.34.self_attn.q_proj.weight\n",
      "- model.layers.34.self_attn.k_proj.weight\n",
      "- model.layers.34.self_attn.v_proj.weight\n",
      "- model.layers.34.self_attn.o_proj.weight\n",
      "- model.layers.34.mlp.gate_proj.weight\n",
      "- model.layers.34.mlp.up_proj.weight\n",
      "- model.layers.34.mlp.down_proj.weight\n",
      "- model.layers.34.input_layernorm.weight\n",
      "- model.layers.34.post_attention_layernorm.weight\n",
      "- model.layers.35.self_attn.q_proj.weight\n",
      "- model.layers.35.self_attn.k_proj.weight\n",
      "- model.layers.35.self_attn.v_proj.weight\n",
      "- model.layers.35.self_attn.o_proj.weight\n",
      "- model.layers.35.mlp.gate_proj.weight\n",
      "- model.layers.35.mlp.up_proj.weight\n",
      "- model.layers.35.mlp.down_proj.weight\n",
      "- model.layers.35.input_layernorm.weight\n",
      "- model.layers.35.post_attention_layernorm.weight\n",
      "- model.layers.36.self_attn.q_proj.weight\n",
      "- model.layers.36.self_attn.k_proj.weight\n",
      "- model.layers.36.self_attn.v_proj.weight\n",
      "- model.layers.36.self_attn.o_proj.weight\n",
      "- model.layers.36.mlp.gate_proj.weight\n",
      "- model.layers.36.mlp.up_proj.weight\n",
      "- model.layers.36.mlp.down_proj.weight\n",
      "- model.layers.36.input_layernorm.weight\n",
      "- model.layers.36.post_attention_layernorm.weight\n",
      "- model.layers.37.self_attn.q_proj.weight\n",
      "- model.layers.37.self_attn.k_proj.weight\n",
      "- model.layers.37.self_attn.v_proj.weight\n",
      "- model.layers.37.self_attn.o_proj.weight\n",
      "- model.layers.37.mlp.gate_proj.weight\n",
      "- model.layers.37.mlp.up_proj.weight\n",
      "- model.layers.37.mlp.down_proj.weight\n",
      "- model.layers.37.input_layernorm.weight\n",
      "- model.layers.37.post_attention_layernorm.weight\n",
      "- model.layers.38.self_attn.q_proj.weight\n",
      "- model.layers.38.self_attn.k_proj.weight\n",
      "- model.layers.38.self_attn.v_proj.weight\n",
      "- model.layers.38.self_attn.o_proj.weight\n",
      "- model.layers.38.mlp.gate_proj.weight\n",
      "- model.layers.38.mlp.up_proj.weight\n",
      "- model.layers.38.mlp.down_proj.weight\n",
      "- model.layers.38.input_layernorm.weight\n",
      "- model.layers.38.post_attention_layernorm.weight\n",
      "- model.layers.39.self_attn.q_proj.weight\n",
      "- model.layers.39.self_attn.k_proj.weight\n",
      "- model.layers.39.self_attn.v_proj.weight\n",
      "- model.layers.39.self_attn.o_proj.weight\n",
      "- model.layers.39.mlp.gate_proj.weight\n",
      "- model.layers.39.mlp.up_proj.weight\n",
      "- model.layers.39.mlp.down_proj.weight\n",
      "- model.layers.39.input_layernorm.weight\n",
      "- model.layers.39.post_attention_layernorm.weight\n",
      "- model.norm.weight\n",
      "- model.mm_projector.0.weight\n",
      "- model.mm_projector.0.bias\n",
      "- model.mm_projector.2.weight\n",
      "- model.mm_projector.2.bias\n",
      "- lm_head.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': '${trainer.precision}', 'micro_batch_size': 16, 'global_batch_size': 128, 'tensor_model_parallel_size': 1, 'pipeline_model_parallel_size': 1, 'virtual_pipeline_model_parallel_size': None, 'restore_from_path': None, 'mm_cfg': {'llm': {'from_pretrained': None, 'freeze': False, 'model_type': 'llama_2'}, 'vision_encoder': {'from_pretrained': 'openai/clip-vit-large-patch14-336', 'from_hf': True, 'patch_dim': 14, 'hidden_size': 1024, 'vision_select_layer': -2, 'class_token_length': 1, 'freeze': True}, 'pretrain_mm_mlp_adapter': None, 'mm_mlp_adapter_type': 'mlp2x_gelu', 'use_im_start_end': False, 'model_type': 'v1'}, 'mcore_gpt': False, 'encoder_seq_length': 4096, 'max_position_embeddings': 4096, 'position_embedding_type': 'rope', 'num_layers': 40, 'hidden_size': 5120, 'ffn_hidden_size': 13824, 'num_attention_heads': 40, 'init_method_std': 0.02, 'use_scaled_init_method': True, 'hidden_dropout': 0.0, 'attention_dropout': 0.0, 'ffn_dropout': 0.0, 'kv_channels': None, 'apply_query_key_layer_scaling': True, 'normalization': 'rmsnorm', 'layernorm_epsilon': 1e-05, 'do_layer_norm_weight_decay': False, 'make_vocab_size_divisible_by': 128, 'pre_process': True, 'post_process': True, 'persist_layer_norm': True, 'bias': False, 'activation': 'fast-swiglu', 'headscale': False, 'transformer_block_type': 'pre_ln', 'normalize_attention_scores': True, 'rotary_percentage': 1.0, 'attention_type': 'multihead', 'share_embeddings_and_output_weights': False, 'overlap_p2p_comm': False, 'batch_p2p_comm': True, 'seq_len_interpolation_factor': None, 'num_query_groups': 40, 'activations_checkpoint_granularity': None, 'activations_checkpoint_method': None, 'activations_checkpoint_num_layers': None, 'num_micro_batches_with_partial_activation_checkpoints': None, 'activations_checkpoint_layers_per_pipeline': None, 'sequence_parallel': False, 'native_amp_init_scale': 4294967296, 'native_amp_growth_interval': 1000, 'hysteresis': 2, 'fp32_residual_connection': False, 'fp16_lm_cross_entropy': False, 'masked_softmax_fusion': True, 'bias_dropout_add_fusion': False, 'use_cpu_initialization': True, 'onnx_safe': False, 'gradient_accumulation_fusion': False, 'openai_gelu': False, 'bias_activation_fusion': False, 'megatron_legacy': False, 'transformer_engine': False, 'fp8': False, 'fp8_e4m3': False, 'fp8_hybrid': False, 'fp8_margin': 0, 'fp8_interval': 1, 'fp8_amax_history_len': 1, 'fp8_amax_compute_algo': 'most_recent', 'use_emha': False, 'megatron_amp_O2': False, 'grad_allreduce_chunk_size_mb': 125, 'grad_div_ar_fusion': True, 'seed': 1234, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'tokenizer': {'library': 'sentencepiece', 'type': None, 'model': '/home/llava-v1.5-13b/tokenizer_neva.model', 'vocab_file': None, 'merge_file': None, 'delimiter': None, 'sentencepiece_legacy': False, 'additional_special_tokens': None}, 'data': {'num_workers': 8, 'dataloader_type': 'cyclic', 'data_path': None, 'lazy_preprocess': True, 'is_multimodal': True, 'sep_image_conv_front': False, 'image_token_len': 576, 'conv_template': 'v1', 'image_folder': None, 'image_aspect_ratio': 'square'}, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'optim': {'name': 'fused_adam', 'lr': 0.002, 'weight_decay': 0.0, 'betas': [0.9, 0.95], 'sched': {'name': 'CosineAnnealing', 'warmup_steps': 140, 'constant_steps': 0, 'min_lr': 2e-05}}}\n",
      "nemo_config: {'precision': 32, 'micro_batch_size': 16, 'global_batch_size': 128, 'tensor_model_parallel_size': 1, 'pipeline_model_parallel_size': 1, 'virtual_pipeline_model_parallel_size': None, 'restore_from_path': None, 'mm_cfg': {'llm': {'from_pretrained': None, 'freeze': False, 'model_type': 'llama_2'}, 'vision_encoder': {'from_pretrained': 'openai/clip-vit-large-patch14-336', 'from_hf': True, 'patch_dim': 14, 'hidden_size': 1024, 'vision_select_layer': -2, 'class_token_length': 1, 'freeze': True}, 'pretrain_mm_mlp_adapter': None, 'mm_mlp_adapter_type': 'mlp2x_gelu', 'use_im_start_end': False, 'model_type': 'v1'}, 'mcore_gpt': False, 'encoder_seq_length': 4096, 'max_position_embeddings': 4096, 'position_embedding_type': 'rope', 'num_layers': 40, 'hidden_size': 5120, 'ffn_hidden_size': 13824, 'num_attention_heads': 40, 'init_method_std': 0.02, 'use_scaled_init_method': True, 'hidden_dropout': 0.0, 'attention_dropout': 0.0, 'ffn_dropout': 0.0, 'kv_channels': None, 'apply_query_key_layer_scaling': True, 'normalization': 'rmsnorm', 'layernorm_epsilon': 1e-05, 'do_layer_norm_weight_decay': False, 'make_vocab_size_divisible_by': 128, 'pre_process': True, 'post_process': True, 'persist_layer_norm': True, 'bias': False, 'activation': 'fast-swiglu', 'headscale': False, 'transformer_block_type': 'pre_ln', 'normalize_attention_scores': True, 'rotary_percentage': 1.0, 'attention_type': 'multihead', 'share_embeddings_and_output_weights': False, 'overlap_p2p_comm': False, 'batch_p2p_comm': True, 'seq_len_interpolation_factor': None, 'num_query_groups': 40, 'activations_checkpoint_granularity': None, 'activations_checkpoint_method': None, 'activations_checkpoint_num_layers': None, 'num_micro_batches_with_partial_activation_checkpoints': None, 'activations_checkpoint_layers_per_pipeline': None, 'sequence_parallel': False, 'native_amp_init_scale': 4294967296, 'native_amp_growth_interval': 1000, 'hysteresis': 2, 'fp32_residual_connection': False, 'fp16_lm_cross_entropy': False, 'masked_softmax_fusion': True, 'bias_dropout_add_fusion': False, 'use_cpu_initialization': True, 'onnx_safe': False, 'gradient_accumulation_fusion': False, 'openai_gelu': False, 'bias_activation_fusion': False, 'megatron_legacy': False, 'transformer_engine': False, 'fp8': False, 'fp8_e4m3': False, 'fp8_hybrid': False, 'fp8_margin': 0, 'fp8_interval': 1, 'fp8_amax_history_len': 1, 'fp8_amax_compute_algo': 'most_recent', 'use_emha': False, 'megatron_amp_O2': False, 'grad_allreduce_chunk_size_mb': 125, 'grad_div_ar_fusion': True, 'seed': 1234, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'tokenizer': {'library': 'sentencepiece', 'type': None, 'model': '/home/llava-v1.5-13b/tokenizer_neva.model', 'vocab_file': None, 'merge_file': None, 'delimiter': None, 'sentencepiece_legacy': False, 'additional_special_tokens': None}, 'data': {'num_workers': 8, 'dataloader_type': 'cyclic', 'data_path': None, 'lazy_preprocess': True, 'is_multimodal': True, 'sep_image_conv_front': False, 'image_token_len': 576, 'conv_template': 'v1', 'image_folder': None, 'image_aspect_ratio': 'square'}, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'optim': {'name': 'fused_adam', 'lr': 0.002, 'weight_decay': 0.0, 'betas': [0.9, 0.95], 'sched': {'name': 'CosineAnnealing', 'warmup_steps': 140, 'constant_steps': 0, 'min_lr': 2e-05}}}\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2024-05-27 22:12:38 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "    \n",
      "converting layer 0\n",
      "done layer 0\n",
      "converting layer 1\n",
      "done layer 1\n",
      "converting layer 2\n",
      "done layer 2\n",
      "converting layer 3\n",
      "done layer 3\n",
      "converting layer 4\n",
      "done layer 4\n",
      "converting layer 5\n",
      "done layer 5\n",
      "converting layer 6\n",
      "done layer 6\n",
      "converting layer 7\n",
      "done layer 7\n",
      "converting layer 8\n",
      "done layer 8\n",
      "converting layer 9\n",
      "done layer 9\n",
      "converting layer 10\n",
      "done layer 10\n",
      "converting layer 11\n",
      "done layer 11\n",
      "converting layer 12\n",
      "done layer 12\n",
      "converting layer 13\n",
      "done layer 13\n",
      "converting layer 14\n",
      "done layer 14\n",
      "converting layer 15\n",
      "done layer 15\n",
      "converting layer 16\n",
      "done layer 16\n",
      "converting layer 17\n",
      "done layer 17\n",
      "converting layer 18\n",
      "done layer 18\n",
      "converting layer 19\n",
      "done layer 19\n",
      "converting layer 20\n",
      "done layer 20\n",
      "converting layer 21\n",
      "done layer 21\n",
      "converting layer 22\n",
      "done layer 22\n",
      "converting layer 23\n",
      "done layer 23\n",
      "converting layer 24\n",
      "done layer 24\n",
      "converting layer 25\n",
      "done layer 25\n",
      "converting layer 26\n",
      "done layer 26\n",
      "converting layer 27\n",
      "done layer 27\n",
      "converting layer 28\n",
      "done layer 28\n",
      "converting layer 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done layer 29\n",
      "converting layer 30\n",
      "done layer 30\n",
      "converting layer 31\n",
      "done layer 31\n",
      "converting layer 32\n",
      "done layer 32\n",
      "converting layer 33\n",
      "done layer 33\n",
      "converting layer 34\n",
      "done layer 34\n",
      "converting layer 35\n",
      "done layer 35\n",
      "converting layer 36\n",
      "done layer 36\n",
      "converting layer 37\n",
      "done layer 37\n",
      "converting layer 38\n",
      "done layer 38\n",
      "converting layer 39\n",
      "done layer 39\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:263] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:269] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:274] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:277] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:285] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:288] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:289] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:296] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:297] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:306] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:310] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:311] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:331] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:343] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:349] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:350] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:351] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_init:352] Rank 0 has embedding rank: 0\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo I 2024-05-27 22:14:15 tokenizer_utils:188] Getting SentencePiece with model: /home/llava-v1.5-13b/tokenizer_neva.model\n",
      "[NeMo I 2024-05-27 22:14:15 megatron_base_model:585] Padded vocab_size: 32128, original vocab_size: 32008, dummy tokens: 120.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:498] apply_query_key_layer_scaling is only enabled when using FP16, setting it to False and setting NVTE_APPLY_QK_LAYER_SCALING=0\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: activation_func_fp8_input_store in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: disable_parameter_transpose_cache in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: enable_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:14:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: rotary_percent in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-27 22:15:28 neva_model:554] Neva model initialized with 13017175040 trainable parameters\n",
      "WARNING: Auto padding model.language_model.embedding.word_embeddings.weight from torch.Size([32000, 5120]) to torch.Size([32128, 5120])\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.embeddings.class_embedding not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.embeddings.patch_embedding.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.embeddings.position_embedding.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.pre_layrnorm.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.pre_layrnorm.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.1.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.2.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.3.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.4.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.5.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.6.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.7.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.8.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.9.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.10.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.11.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.12.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.13.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.14.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.15.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.16.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.17.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.18.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.19.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.20.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.21.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.22.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.self_attn.k_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.self_attn.k_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.self_attn.v_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.self_attn.v_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.self_attn.q_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.self_attn.q_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.self_attn.out_proj.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.self_attn.out_proj.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.layer_norm1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.layer_norm1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.mlp.fc1.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.mlp.fc1.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.mlp.fc2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.mlp.fc2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.layer_norm2.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.23.layer_norm2.bias not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.post_layernorm.weight not in checkpoint but in model.\n",
      "Unexpected key: model.language_model.embedding.word_embeddings.vision_encoder.vision_model.post_layernorm.bias not in checkpoint but in model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Auto padding model.language_model.output_layer.weight from torch.Size([32000, 5120]) to torch.Size([32128, 5120])\n",
      "[NeMo I 2024-05-27 22:17:29 convert_hf_llava_to_neva:361] NeMo model saved to: /home/llava_v1.5_13b_converted/llava-v1.5-13b-2403.nemo\n"
     ]
    }
   ],
   "source": [
    "## Step 5: convert checkpoints to .nemo\n",
    "!python /opt/NeMo/examples/multimodal/multimodal_llm/neva/convert_hf_llava_to_neva.py \\\n",
    " --in-file /home/llava-v1.5-13b \\\n",
    " --out-file /home/llava_v1.5_13b_converted/llava-v1.5-13b-2403.nemo \\\n",
    " --tokenizer-model /home/llava-v1.5-13b/tokenizer_neva.model \\\n",
    " --conv-template v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78d20dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention Installed\n",
      "[NeMo W 2024-05-27 22:38:35 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2024-05-27 22:38:38 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n",
      "[NeMo I 2024-05-27 22:38:38 neva_peft:31] \n",
      "    \n",
      "    ************** Experiment configuration ***********\n",
      "[NeMo I 2024-05-27 22:38:38 neva_peft:32] \n",
      "    name: nemo_neva\n",
      "    restore_from_path: null\n",
      "    trainer:\n",
      "      devices: 1\n",
      "      num_nodes: 1\n",
      "      accelerator: gpu\n",
      "      precision: bf16\n",
      "      logger: false\n",
      "      enable_checkpointing: false\n",
      "      use_distributed_sampler: false\n",
      "      max_epochs: -1\n",
      "      max_steps: 50\n",
      "      log_every_n_steps: 1\n",
      "      val_check_interval: 10\n",
      "      check_val_every_n_epoch: null\n",
      "      limit_val_batches: 10\n",
      "      limit_test_batches: 500\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 1.0\n",
      "      benchmark: false\n",
      "      enable_model_summary: false\n",
      "    exp_manager:\n",
      "      explicit_log_dir: null\n",
      "      exp_dir: null\n",
      "      name: nemo_neva\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        project: null\n",
      "        name: null\n",
      "      resume_if_exists: true\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      resume_from_checkpoint: ${model.resume_from_checkpoint}\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        monitor: val_loss\n",
      "        save_top_k: 10\n",
      "        mode: min\n",
      "        always_save_nemo: false\n",
      "        save_nemo_on_train_end: true\n",
      "        filename: megatron_clip--{val_loss:.2f}-{step}-{consumed_samples}\n",
      "        model_parallel_size: ${multiply:${model.tensor_model_parallel_size}, ${model.pipeline_model_parallel_size}}\n",
      "      ema:\n",
      "        enable: false\n",
      "        decay: 0.9999\n",
      "        validate_original_weights: false\n",
      "        every_n_steps: 1\n",
      "        cpu_offload: false\n",
      "    model:\n",
      "      precision: ${trainer.precision}\n",
      "      micro_batch_size: 4\n",
      "      global_batch_size: 32\n",
      "      tensor_model_parallel_size: 1\n",
      "      pipeline_model_parallel_size: 1\n",
      "      virtual_pipeline_model_parallel_size: null\n",
      "      restore_from_path: /home/llava_v1.5_13b_converted/llava-v1.5-13b-2403.nemo\n",
      "      mm_cfg:\n",
      "        llm:\n",
      "          from_pretrained: null\n",
      "          freeze: true\n",
      "          model_type: nvgpt\n",
      "        vision_encoder:\n",
      "          from_pretrained: openai/clip-vit-large-patch14\n",
      "          from_hf: true\n",
      "          patch_dim: 14\n",
      "          hidden_size: 1024\n",
      "          vision_select_layer: -2\n",
      "          class_token_length: 1\n",
      "          freeze: true\n",
      "        pretrain_mm_mlp_adapter: null\n",
      "        mm_mlp_adapter_type: linear\n",
      "        use_im_start_end: false\n",
      "      peft:\n",
      "        peft_scheme: lora\n",
      "        restore_from_path: null\n",
      "        lora_tuning:\n",
      "          adapter_dim: 32\n",
      "          adapter_dropout: 0.0\n",
      "          column_init_method: xavier\n",
      "          row_init_method: zero\n",
      "          layer_selection: null\n",
      "          weight_tying: false\n",
      "          position_embedding_strategy: null\n",
      "      mcore_gpt: false\n",
      "      encoder_seq_length: 4096\n",
      "      max_position_embeddings: ${.encoder_seq_length}\n",
      "      position_embedding_type: rope\n",
      "      num_layers: 40\n",
      "      hidden_size: 5120\n",
      "      ffn_hidden_size: 13824\n",
      "      num_attention_heads: 40\n",
      "      init_method_std: 0.014\n",
      "      use_scaled_init_method: true\n",
      "      hidden_dropout: 0.0\n",
      "      attention_dropout: 0.0\n",
      "      kv_channels: null\n",
      "      apply_query_key_layer_scaling: true\n",
      "      normalization: rmsnorm\n",
      "      layernorm_epsilon: 1.0e-05\n",
      "      do_layer_norm_weight_decay: false\n",
      "      pre_process: true\n",
      "      post_process: true\n",
      "      persist_layer_norm: true\n",
      "      bias: false\n",
      "      activation: fast-swiglu\n",
      "      headscale: false\n",
      "      transformer_block_type: pre_ln\n",
      "      normalize_attention_scores: true\n",
      "      rotary_percentage: 1.0\n",
      "      attention_type: multihead\n",
      "      share_embeddings_and_output_weights: false\n",
      "      overlap_p2p_comm: false\n",
      "      batch_p2p_comm: true\n",
      "      seq_len_interpolation_factor: null\n",
      "      num_query_groups: null\n",
      "      activations_checkpoint_granularity: null\n",
      "      activations_checkpoint_method: null\n",
      "      activations_checkpoint_num_layers: null\n",
      "      num_micro_batches_with_partial_activation_checkpoints: null\n",
      "      activations_checkpoint_layers_per_pipeline: null\n",
      "      sequence_parallel: false\n",
      "      native_amp_init_scale: 4294967296\n",
      "      native_amp_growth_interval: 1000\n",
      "      hysteresis: 2\n",
      "      fp32_residual_connection: false\n",
      "      fp16_lm_cross_entropy: false\n",
      "      masked_softmax_fusion: true\n",
      "      bias_dropout_add_fusion: false\n",
      "      use_cpu_initialization: false\n",
      "      onnx_safe: false\n",
      "      gradient_accumulation_fusion: false\n",
      "      openai_gelu: false\n",
      "      bias_activation_fusion: false\n",
      "      megatron_legacy: false\n",
      "      transformer_engine: false\n",
      "      fp8: false\n",
      "      fp8_e4m3: false\n",
      "      fp8_hybrid: false\n",
      "      fp8_margin: 0\n",
      "      fp8_interval: 1\n",
      "      fp8_amax_history_len: 1\n",
      "      fp8_amax_compute_algo: most_recent\n",
      "      use_emha: false\n",
      "      megatron_amp_O2: true\n",
      "      grad_allreduce_chunk_size_mb: 125\n",
      "      grad_div_ar_fusion: true\n",
      "      seed: 1234\n",
      "      resume_from_checkpoint: null\n",
      "      apex_transformer_log_level: 30\n",
      "      gradient_as_bucket_view: true\n",
      "      tokenizer:\n",
      "        library: sentencepiece\n",
      "        type: GPT2BPETokenizer\n",
      "        model: /home/llava-v1.5-13b/tokenizer_neva.model\n",
      "        vocab_file: null\n",
      "        merge_file: null\n",
      "        delimiter: null\n",
      "        sentencepiece_legacy: false\n",
      "      data:\n",
      "        num_workers: 0\n",
      "        dataloader_type: cyclic\n",
      "        data_path: /home/LLaVA-Instruct-mixture/llava_v1_5_mix665k_trimmed.json\n",
      "        lazy_preprocess: true\n",
      "        is_multimodal: true\n",
      "        sep_image_conv_front: false\n",
      "        image_token_len: 256\n",
      "        conv_template: llama_2\n",
      "        image_folder: /home/LLaVA-Instruct-mixture/images\n",
      "        image_aspect_ratio: square\n",
      "      nsys_profile:\n",
      "        enabled: false\n",
      "        start_step: 10\n",
      "        end_step: 10\n",
      "        ranks:\n",
      "        - 0\n",
      "        gen_shape: false\n",
      "      optim:\n",
      "        name: fused_adam\n",
      "        lr: 0.0002\n",
      "        weight_decay: 0.0\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.95\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 200\n",
      "          constant_steps: 0\n",
      "          min_lr: 2.0e-07\n",
      "    cluster_type: interactive\n",
      "    \n",
      "[NeMo W 2024-05-27 22:38:38 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/_graveyard/precision.py:49: The `MixedPrecisionPlugin` is deprecated. Use `pytorch_lightning.plugins.precision.MixedPrecision` instead.\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2024-05-27 22:38:38 exp_manager:773] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo W 2024-05-27 22:38:38 exp_manager:630] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :/home/nemo_experiments/nemo_neva/checkpoints. Training from scratch.\n",
      "[NeMo I 2024-05-27 22:38:38 exp_manager:396] Experiments will be logged at /home/nemo_experiments/nemo_neva\n",
      "[NeMo I 2024-05-27 22:38:38 exp_manager:856] TensorboardLogger has been set up\n",
      "[NeMo W 2024-05-27 22:38:38 exp_manager:966] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 50. Please ensure that max_steps will run for at least None epochs to ensure that checkpointing will not error out.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:263] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:269] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:274] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:277] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:285] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:288] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:289] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:296] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:297] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:306] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:310] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:311] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:331] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:343] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:349] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:350] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:351] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_init:352] Rank 0 has embedding rank: 0\n",
      "24-05-27 22:39:15 - PID:27965 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 8\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo I 2024-05-27 22:39:15 tokenizer_utils:188] Getting SentencePiece with model: /home/llava-v1.5-13b/tokenizer_neva.model\n",
      "[NeMo I 2024-05-27 22:39:15 megatron_base_model:585] Padded vocab_size: 32128, original vocab_size: 32008, dummy tokens: 120.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:498] apply_query_key_layer_scaling is only enabled when using FP16, setting it to False and setting NVTE_APPLY_QK_LAYER_SCALING=0\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: activation_func_fp8_input_store in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: disable_parameter_transpose_cache in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: enable_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: rotary_percent in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:39:15 megatron_gpt_model:311] megatron_amp_O2 is enabled but transformer-engine is not.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-27 22:39:16 neva_model:554] Neva model initialized with 0 trainable parameters\n",
      "[NeMo W 2024-05-27 22:39:47 neva_model:943] Loading state dict for MegatronNevaModel...\n",
      "[NeMo W 2024-05-27 22:39:53 neva_model:947] Missing keys were detected during the load. Please double check.\n",
      "[NeMo W 2024-05-27 22:39:53 neva_model:949] Missing keys: ['model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.embeddings.class_embedding', 'model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.embeddings.patch_embedding.weight', 'model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.embeddings.position_embedding.weight', 'model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.pre_layrnorm.weight', 'model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.pre_layrnorm.bias', 'model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.module.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.q_proj.weight'] and 778 more.\n",
      "[NeMo C 2024-05-27 22:39:53 neva_model:953] Unexpected keys were detected during the load. Please double check.\n",
      "[NeMo C 2024-05-27 22:39:53 neva_model:954] Unexpected keys: \n",
      "    ['model.module.language_model.embedding.word_embeddings.adapter_layer.mm_projector_adapter.mm_projector.2.weight', 'model.module.language_model.embedding.word_embeddings.adapter_layer.mm_projector_adapter.mm_projector.2.bias', 'model.module.language_model.embedding.word_embeddings.adapter_layer.mm_projector_adapter.mm_projector.0.weight', 'model.module.language_model.embedding.word_embeddings.adapter_layer.mm_projector_adapter.mm_projector.0.bias']\n",
      "[NeMo I 2024-05-27 22:39:53 nlp_overrides:1157] Model MegatronNevaModel was successfully restored from /home/llava_v1.5_13b_converted/llava-v1.5-13b-2403.nemo.\n",
      "[NeMo I 2024-05-27 22:39:53 neva_peft:58] Adding adapter weights to the model for PEFT\n",
      "[NeMo I 2024-05-27 22:39:53 multimodal_adapter_mixins:64] Before adding PEFT params:\n",
      "      | Name  | Type          | Params\n",
      "    ----------------------------------------\n",
      "    0 | model | Float16Module | 13.3 B\n",
      "    ----------------------------------------\n",
      "    5.2 M     Trainable params\n",
      "    13.3 B    Non-trainable params\n",
      "    13.3 B    Total params\n",
      "    53,302.411Total estimated model params size (MB)\n",
      "[NeMo I 2024-05-27 22:39:57 multimodal_adapter_mixins:77] After adding PEFT params:\n",
      "      | Name  | Type          | Params\n",
      "    ----------------------------------------\n",
      "    0 | model | Float16Module | 13.4 B\n",
      "    ----------------------------------------\n",
      "    31.5 M    Trainable params\n",
      "    13.3 B    Non-trainable params\n",
      "    13.4 B    Total params\n",
      "    53,407.269Total estimated model params size (MB)\n",
      "[NeMo W 2024-05-27 22:39:57 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:181: You have overridden `MegatronNevaModel.configure_sharded_model` which is deprecated. Please override the `configure_model` hook instead. Instantiation with the newer hook will be created on the device right away and have the right data type depending on the precision setting in the Trainer.\n",
      "    \n",
      "[NeMo W 2024-05-27 22:39:57 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:163: You are using the `dataloader_iter` step flavor. If you consume the iterator more than once per step, the `batch_idx` argument in any hook that takes it will not match with the batch index of the last batch consumed. This might have unforeseen effects on callbacks or code that expects to get the correct index. This will also not work well with gradient accumulation. This feature is very experimental and subject to change. Here be dragons.\n",
      "    \n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2024-05-27 22:39:58 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/nemo_experiments/nemo_neva/checkpoints exists and is not empty.\n",
      "    \n",
      "[NeMo I 2024-05-27 22:39:58 neva_model:799] Pipeline model parallel rank: 0, Tensor model parallel rank: 0, Number of model parameters on device: 1.34e+10. Total number of model parameters: 1.34e+10.\n",
      "[NeMo I 2024-05-27 22:39:58 neva_model:863] Building Neva datasets.\n",
      "Loading data...\n",
      "Loading data...\n",
      "Formatting inputs...Skip in lazy mode\n",
      "[NeMo I 2024-05-27 22:39:58 megatron_gpt_model:1526] Setting up train dataloader with len(len(self._train_ds)): 43 and consumed samples: 0\n",
      "[NeMo I 2024-05-27 22:39:58 neva_model:875] Building dataloader with consumed samples: 0\n",
      "[NeMo I 2024-05-27 22:39:58 data_samplers:76] Instantiating MegatronPretrainingSampler with total_samples: 43 and consumed_samples: 0\n",
      "[NeMo I 2024-05-27 22:39:58 megatron_gpt_model:1534] Setting up validation dataloader with len(len(self._validation_ds)): 43 and consumed samples: 0\n",
      "[NeMo I 2024-05-27 22:39:58 neva_model:875] Building dataloader with consumed samples: 0\n",
      "[NeMo I 2024-05-27 22:39:58 data_samplers:76] Instantiating MegatronPretrainingSampler with total_samples: 43 and consumed_samples: 0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[NeMo I 2024-05-27 22:39:58 modelPT:724] Optimizer config = FusedAdam (\n",
      "    Parameter Group 0\n",
      "        betas: [0.9, 0.95]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        is_expert: False\n",
      "        lr: 0.0002\n",
      "        weight_decay: 0.0\n",
      "    \n",
      "    Parameter Group 1\n",
      "        betas: [0.9, 0.95]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        is_expert: False\n",
      "        lr: 0.0002\n",
      "        weight_decay: 0.0\n",
      "    )\n",
      "[NeMo I 2024-05-27 22:39:58 lr_scheduler:923] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7efe35d9f9d0>\" \n",
      "    will be used during training (effective maximum steps = 50) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 200\n",
      "    constant_steps: 0\n",
      "    min_lr: 2.0e-07\n",
      "    max_steps: 50\n",
      "    )\n",
      "[NeMo I 2024-05-27 22:39:58 lr_scheduler:923] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7efe35de5f00>\" \n",
      "    will be used during training (effective maximum steps = 50) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 200\n",
      "    constant_steps: 0\n",
      "    min_lr: 2.0e-07\n",
      "    max_steps: 50\n",
      "    )\n",
      "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s][NeMo W 2024-05-27 22:39:58 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=223` in the `DataLoader` to improve performance.\n",
      "    \n",
      "[NeMo W 2024-05-27 22:39:58 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py:149: Found `dataloader_iter` argument in the `validation_step`. Note that the support for this signature is experimental and the behavior is subject to change.\n",
      "    \n",
      "[NeMo W 2024-05-27 22:39:59 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=223` in the `DataLoader` to improve performance.\n",
      "    \n",
      "[NeMo W 2024-05-27 22:39:59 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py:149: Found `dataloader_iter` argument in the `training_step`. Note that the support for this signature is experimental and the behavior is subject to change.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.660, global_step[NeMo W 2024-05-27 22:40:03 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 2: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.680, global_step[NeMo W 2024-05-27 22:40:07 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 3: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.680, global_step[NeMo W 2024-05-27 22:40:11 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 4: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.630, global_step[NeMo W 2024-05-27 22:40:15 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 5: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.650, global_step[NeMo W 2024-05-27 22:40:20 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 6: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.610, global_step[NeMo W 2024-05-27 22:40:24 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 7: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.550, global_step[NeMo W 2024-05-27 22:40:28 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 8: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.480, global_step[NeMo W 2024-05-27 22:40:34 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 9: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.340, global_step[NeMo W 2024-05-27 22:40:39 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 10: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.300, global_ste[NeMo W 2024-05-27 22:40:43 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 11: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=3.240, global_ste[NeMo W 2024-05-27 22:40:48 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 12: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=2.700, global_ste[NeMo W 2024-05-27 22:40:53 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 13: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=2.580, global_ste[NeMo W 2024-05-27 22:40:57 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 14: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=2.500, global_ste[NeMo W 2024-05-27 22:41:01 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 15: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=2.400, global_ste[NeMo W 2024-05-27 22:41:05 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 16: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=2.340, global_ste[NeMo W 2024-05-27 22:41:09 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 17: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=2.270, global_ste[NeMo W 2024-05-27 22:41:14 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 18: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=2.190, global_ste[NeMo W 2024-05-27 22:41:19 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 19: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=2.080, global_ste[NeMo W 2024-05-27 22:41:24 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 20: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.910, global_ste[NeMo W 2024-05-27 22:41:29 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 21: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.850, global_ste[NeMo W 2024-05-27 22:41:33 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 22: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.720, global_ste[NeMo W 2024-05-27 22:41:38 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 23: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.630, global_ste[NeMo W 2024-05-27 22:41:43 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 24: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.590, global_ste[NeMo W 2024-05-27 22:41:47 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 25: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.540, global_ste[NeMo W 2024-05-27 22:41:52 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 26: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.480, global_ste[NeMo W 2024-05-27 22:41:57 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 27: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.410, global_ste[NeMo W 2024-05-27 22:42:01 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 28: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.340, global_ste[NeMo W 2024-05-27 22:42:05 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 29: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.320, global_ste[NeMo W 2024-05-27 22:42:10 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 30: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.230, global_ste[NeMo W 2024-05-27 22:42:15 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 31: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.190, global_ste[NeMo W 2024-05-27 22:42:19 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 32: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.130, global_ste[NeMo W 2024-05-27 22:42:24 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 33: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.120, global_ste[NeMo W 2024-05-27 22:42:28 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 34: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.070, global_ste[NeMo W 2024-05-27 22:42:32 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.030, global_ste[NeMo W 2024-05-27 22:42:37 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 36: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=1.020, global_ste[NeMo W 2024-05-27 22:42:42 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 37: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=0.950, global_ste[NeMo W 2024-05-27 22:42:46 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 38: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=0.945, global_ste[NeMo W 2024-05-27 22:42:50 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 39: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=0.928, global_ste[NeMo W 2024-05-27 22:42:55 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "Epoch 40: :   0%| | 0/50 [00:00<?, v_num=2, reduced_train_loss=0.853, global_ste[NeMo W 2024-05-27 22:42:59 exp_manager:196] Timer `train_step_timing` was not correctly stopped, suggesting a possible issue. The timer will be reset for now.\n",
      "^C\n",
      "[2024-05-27 22:43:01,794] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n",
      "[2024-05-27 22:43:01,794] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 27965 closing signal SIGINT\n",
      "[NeMo W 2024-05-27 22:43:01 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "## Step 6: Run PEFT\n",
    "! torchrun --nproc_per_node=1 /opt/NeMo/examples/multimodal/multimodal_llm/neva/neva_peft.py \\\n",
    "++cluster_type=interactive \\\n",
    "trainer.precision=bf16 \\\n",
    "model.megatron_amp_O2=True \\\n",
    "trainer.num_nodes=1 \\\n",
    "trainer.devices=1 \\\n",
    "trainer.val_check_interval=50 \\\n",
    "trainer.limit_val_batches=10 \\\n",
    "trainer.log_every_n_steps=1 \\\n",
    "trainer.max_steps=4600 \\\n",
    "model.micro_batch_size=2 \\\n",
    "model.global_batch_size=32 \\\n",
    "model.micro_batch_size=4 \\\n",
    "model.global_batch_size=32 \\\n",
    "model.tensor_model_parallel_size=1 \\\n",
    "model.pipeline_model_parallel_size=1 \\\n",
    "model.mcore_gpt=False \\\n",
    "exp_manager.create_checkpoint_callback=True \\\n",
    "model.data.data_path=/home/LLaVA-Instruct-mixture/llava_v1_5_mix665k_trimmed.json \\\n",
    "model.data.image_folder=/home/LLaVA-Instruct-mixture/images \\\n",
    "model.tokenizer.library=sentencepiece \\\n",
    "model.tokenizer.model=/home/llava-v1.5-13b/tokenizer_neva.model \\\n",
    "model.num_layers=40 \\\n",
    "model.hidden_size=5120 \\\n",
    "model.ffn_hidden_size=13824 \\\n",
    "model.num_attention_heads=40 \\\n",
    "model.normalization=rmsnorm \\\n",
    "model.data.num_workers=0 \\\n",
    "model.rotary_percentage=1.0 \\\n",
    "model.data.conv_template=llama_2 \\\n",
    "model.mm_cfg.vision_encoder.from_pretrained='openai/clip-vit-large-patch14' \\\n",
    "model.mm_cfg.llm.from_pretrained=null \\\n",
    "model.restore_from_path=/home/llava_v1.5_13b_converted/llava-v1.5-13b-2403.nemo \\\n",
    "++exp_manager.checkpoint_callback_params.save_nemo_on_train_end=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b9bb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7 Evaluation / Inference\n",
    "##Before beginning inference, ensure that you have prepared the prompt file and organized the images into a specified folder. Below is an example of how your prompt file should look:\n",
    "import json\n",
    "\n",
    "# Define the data\n",
    "data = {\n",
    "    \"image\": \"000000000009.jpg\",\n",
    "    \"prompt\": \"<image>\\nCan you describe this image?\"\n",
    "}\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"test.jsonl\"\n",
    "\n",
    "# Write the content to the JSONL file\n",
    "with open(file_path, \"w\") as jsonl_file:\n",
    "    jsonl_file.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be9792bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention Installed\n",
      "[NeMo W 2024-05-27 22:55:40 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2024-05-27 22:55:42 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n",
      "[NeMo W 2024-05-27 22:55:43 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:563: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "    \n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:263] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:269] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:274] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:277] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:285] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:288] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:289] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:296] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:297] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:306] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:310] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:311] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:331] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:343] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:349] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:350] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:351] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_init:352] Rank 0 has embedding rank: 0\n",
      "24-05-27 22:56:20 - PID:30966 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 8\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo I 2024-05-27 22:56:20 tokenizer_utils:188] Getting SentencePiece with model: /tmp/tmprov_eais/22aa14bbb6cb42208aec43cefa7d9971_tokenizer_neva.model\n",
      "[NeMo I 2024-05-27 22:56:20 megatron_base_model:585] Padded vocab_size: 32128, original vocab_size: 32008, dummy tokens: 120.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:1146] The model: MegatronNevaModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:498] apply_query_key_layer_scaling is only enabled when using FP16, setting it to False and setting NVTE_APPLY_QK_LAYER_SCALING=0\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: activation_func_fp8_input_store in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: disable_parameter_transpose_cache in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: enable_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n",
      "[NeMo W 2024-05-27 22:56:20 megatron_base_model:557] The model: MegatronNevaModel() does not have field.name: rotary_percent in its cfg. Add this key to cfg or config_mapping to make to make it configurable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-27 22:56:21 neva_model:554] Neva model initialized with 13017175040 trainable parameters\n",
      "[NeMo W 2024-05-27 22:56:51 neva_model:943] Loading state dict for MegatronNevaModel...\n",
      "[NeMo W 2024-05-27 22:56:57 neva_model:947] Missing keys were detected during the load. Please double check.\n",
      "[NeMo W 2024-05-27 22:56:57 neva_model:949] Missing keys: ['model.language_model.embedding.word_embeddings.vision_encoder.vision_model.embeddings.class_embedding', 'model.language_model.embedding.word_embeddings.vision_encoder.vision_model.embeddings.patch_embedding.weight', 'model.language_model.embedding.word_embeddings.vision_encoder.vision_model.embeddings.position_embedding.weight', 'model.language_model.embedding.word_embeddings.vision_encoder.vision_model.pre_layrnorm.weight', 'model.language_model.embedding.word_embeddings.vision_encoder.vision_model.pre_layrnorm.bias', 'model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.language_model.embedding.word_embeddings.vision_encoder.vision_model.encoder.layers.0.self_attn.q_proj.weight'] and 778 more.\n",
      "[NeMo I 2024-05-27 22:56:57 nlp_overrides:1157] Model MegatronNevaModel was successfully restored from /home/llava_v1.5_13b_converted/llava-v1.5-13b-2403.nemo.\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2024-05-27 22:56:59 nemo_logging:349] /opt/NeMo/nemo/collections/nlp/modules/common/text_generation_strategy.py:466: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "      context_tokens_tensor = torch.cuda.LongTensor(context_tokens)\n",
      "    \n",
      "[NeMo W 2024-05-27 22:57:00 nemo_logging:349] /opt/NeMo/nemo/collections/nlp/modules/common/text_generation_utils.py:397: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "      string_tensor = torch.as_tensor(\n",
      "    \n",
      "[NeMo W 2024-05-27 22:57:00 nemo_logging:349] /opt/apex/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n",
      "------------- PROMPT 0 of 1 ------------ \n",
      "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: <image>\n",
      "\n",
      "Can you describe this image? ASSISTANT: The image features a dining table with four plastic containers filled with various food items. The containers are arranged in a way that they are easily accessible and visible. Each container has a different type of food, including fruits, vegetables, and bread. \n",
      "\n",
      "In one container, there are several pieces of broccoli, while another container has a variety of fruits such as apples and oranges. The third container holds a sandwich, and the fourth container has a mix of vegetables and bread. The arrangement of these containers creates a visually appealing and organized display of food.\n",
      "\n",
      "CLEAN RESPONSE: The image features a dining table with four plastic containers filled with various food items. The containers are arranged in a way that they are easily accessible and visible. Each container has a different type of food, including fruits, vegetables, and bread. \n",
      "\n",
      "In one container, there are several pieces of broccoli, while another container has a variety of fruits such as apples and oranges. The third container holds a sandwich, and the fourth container has a mix of vegetables and bread. The arrangement of these containers creates a visually appealing and organized display of food.\n",
      "---------------------------------------------\n",
      "\n",
      "Error executing job with overrides: ['tensor_model_parallel_size=1', 'pipeline_model_parallel_size=1', 'neva_model_file=/home/llava_v1.5_13b_converted/llava-v1.5-13b-2403.nemo', 'trainer.devices=1', 'trainer.precision=bf16', 'prompt_file=./test.jsonl', 'inference.images_base_path=/home/LLaVA-Instruct-mixture/images/coco/train2017']\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/NeMo/examples/multimodal/multimodal_llm/neva/neva_evaluation.py\", line 137, in main\n",
      "    with open(cfg.output_file, 'w') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/pwd/nemo_experiments/results.jsonl'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "[2024-05-27 22:57:15,267] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 30966) of binary: /usr/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 812, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 803, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 135, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 268, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "/opt/NeMo/examples/multimodal/multimodal_llm/neva/neva_evaluation.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-05-27_22:57:15\n",
      "  host      : e8e60e4d7efd\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 30966)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONPATH'] = os.environ.get('PYTHONPATH', '') + ':/opt/NeMo'\n",
    "!torchrun --nproc_per_node=1 /opt/NeMo/examples/multimodal/multimodal_llm/neva/neva_evaluation.py \\\n",
    "tensor_model_parallel_size=1 \\\n",
    "pipeline_model_parallel_size=1 \\\n",
    "neva_model_file=/home/nemo_experiments/nemo_neva/checkpoints/nemo_neva.nemo \\\n",
    "trainer.devices=1 \\\n",
    "trainer.precision=bf16 \\\n",
    "prompt_file=./test.jsonl \\\n",
    "inference.images_base_path=/home/LLaVA-Instruct-mixture/images/coco/train2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9b771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
